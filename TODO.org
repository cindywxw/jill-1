

* DONE fix storage of uuids

storing uuids as 16-byte strings is problematic because of nulls. change
specification to be either a 36-byte hex representation or a 128-bit integer.
The latter isn't supported on all platforms.

* DONE profile arf thread

using test_arf_thread I find a limit to how many channels I can write
simultaneously without causing buffer overruns. 100 is too many. Increasing the
JACK period size to 2048 helps. May need to increase ringbuffer size as well,
though I also got a malloc error when I tried to do 200 channels with a 2048
period.  The compression setting doesn't seem to make a difference.  Need to do
some serious profiling.

The first step is to try to factor out the jack client code so that the disk
code can be tested without needing to connect to the jack daemon.  It would
also be good to encapsulate as much of the mutex logic as possible.

I'm doing a rudimentary performance test by measuring how much have to throttle
back the fast thread in order not to have any xruns. For the "dummy writer",
which just talks to stdout, it seems like as long as the buffer is at least 5
times the size of the period, we only need a 1 ns throttle (plus whatever time
it takes to look up the current time). A 1024 sample period is ~ 200 us at 48
kHz, so this is more than fast enough for >256 channels.

Well, it makes a difference if I actually allow the data to go to stdout
instead of just redirecting to /dev/null. With no optimizations, a 20x buffer
needs a throttle of 4051 ns.

Let's see how the arf thread does.

With no optimizations I can do 12 channels and gzip1 compression with no
problems. Closing this for now.

* DONE fix port registration / buffer size bug

This is an annoying one. jack_client maintains a list of ports it has
registered, which it updates through the a port registration callback. This is a
nice solution that maintains a realtime-safe access point for the port list, but
these callbacks don't actually get called until the client is activated and
typically after the buffer size callback. In jrecord I'm using the buffer size
callback to adjust the size of the ringbuffer, but on the first call it doesn't
know how many ports are registered.

Fixed this by moving the port bookkeeping code to the register/unregister
functions. This should result in no loss of flexibility b/c other clients
shouldn't be doing anything with a module's ports anyway.

* DONE fix storage of event types

Event data will be stored in arrays with a compound datatype. Empty events are
discarded. Because the length of the message may vary, the bytes after the
status byte need to be stored in a variable length type. However, h5py cannot
read vlen types that are not strings!  Storing all event data in strings is
problematic, though, because normal MIDI messages are not null-terminated and
may in fact have \0 in them at various places.  Options are:

1. store the data in the correct format (char vlens) and try to fix h5py.
   definitely non-trivial.
2. translate all events into hex-encoded strings. This is pretty hacky and
   doubles the storage size.
3. translate standard midi messages into strings, e.g. "note on: 64 00".
   Probably the worst option because it locks in a specific interpretation of
   the messages

I think #2 is the best option at the moment, with a note that #1 may be
supported in the future.  I'm only going to require hex encoding for MIDI
messages with non-string payloads

* CANCELED abstract jack_client class?

should we anticipate non-jack data sources? Might make it easier to test.
However, there is a lot of jack-specific code elsewhere that would need to be
tracked down, including some of the major types that depend on JACK. See below.

* DONE write trigger logic for arf_writer

This is moderately tricky because of the prebuffer. The function needs to

1) check whether the period is from the trigger port
2) if recording:
   1) if there was an offset event write data up to offset + postbuffer; copy
      remainder to prebuffer
   2) else, write all data
3) else:
   1) if there was an onset event, write data from prebuffer plus rest of period
   2) else, copy data to prebuffer

It's complicated enough I'm going to move the logic into a derived class. The
common logic for writing a period is now in do_write.

May be difficult to unit test this, although I can probably safely factor out
the prebuffering code.

The prebuffer is essentially a deque of period buffers.  We copy out the data
from the ringbuffer and put it in the queue.  When data falls off the end of
the queue it's released.  Really this should be implemented with a pool of
reusable memory to avoid calling malloc excessively.

Another option would be to allocate the ringbuffer large enough to hold the
prebuffer, and then simply retain the periods until they are far enough in the
past to discard.  The current implementation/interface isn't quite right for
this.

I wonder, what if I reimplemented the period ringbuffer using preallocated
structs rather than serializing. Instead of managing read/write pointers I'd be
managing a memory pool. Resizing the buffer would be messy because each of the
elements would have to be reallocated, but in practice this is not going to
happen much....okay, scratch this - it's really not much help - the real issue
is how =multichannel_writer= handles old data.

I think the thing to do is abstract the release operation through a virtual
function; deriving classes could then choose to hang on to extra frames. Or
implement a release() function in MCW that the write() funciton would call. Not
sure which is best practice, although the latter preserves encapsulation a bit
better.

Getting there...the period_ringbuffer class needs to be tweaked a bit to make it
useful as a prebuffer. Basically we need two read pointers - one that tracks the
"current" time, and another that is only advanced when the resources are
released.  Semantics of the interface should look something like this:

+ peek_newest - access the newest period and advance the peek pointer
+ peek_oldest - access the oldest period in the queue
+ release_oldest - advance the read pointer, releasing the oldest period in the queue
+ release_all - discard the data in the read buffer (e.g. when there is an xrun)

[2013-03-25 Mon] Good progress today, with many roadblocks. prebuffering works
great. post-trigger recording, not so much.  it's very tricky to figure out when
to terminate the recording, partly due to the annoyance of unsigned integer
arithemetic that needs to support overflow, and partly due to the fact that a
single period with multiple channels gets spread across multiple calls to
triggered_arf_thread::write().  One option would be to just drop the
post-trigger logic and force the upstream module generating events to wait
before issuing the offset.  This is simple but could lack some flexibility in
the future.

What the logic needs to do is figure out how many samples from the current
period need to be written, and if no samples need to be written, close the
entry.  There are three relevant variables: time at start of period; frames in
the period; and time of the offset event.

To deal with overflows, let's operate with deltas whenever possible, so
calculate (start - offset) and (start - offset + nframes).  The first of these
will overflow if the offset occurred in the current period

If start < offset < end, the offset event occurred in the current period. The
number of samples to be written is min(offset - start + npost, end - start)

[2013-03-26 Tue] Well, it's actually fairly simple. After the trigger I store
offset + posttrigger (i.e. the time to stop recording). In each successive
period I compare this value with the current time to determine whether this time
point has elapsed. The result of the comparison has to be stored in a signed
variable in case the offset occurred in the period before an overflow.  If it's
negative, then the offset has passed and the entry can be closed.

* DONE fix assertion failure in triggered_arf_thread

the failed assertion is that all the periods in the tail of the queue have been
flushed by the start_recording function.  I think it's failing because of how
the ringbuffer is implemented using mirrored memory - the same object can be
accessed by pointers with entirely different addresses, so the comparison can't
be made using addresses.

* DONE fix corrupted event

for some reason the first event stored by arf_writer is not properly stored and
appears as a bunch of junk

pathetic. was trying to store data from a stack-allocated string that went out
of scope.

* DONE refactor to create some better abstractions

Without necessarily trying to anticipate all possible data sources, etc, it
would be good at this stage to try to define some interfaces.  The challenge is
to try to limit the degree to which they have to interact with each other.  As
always, logging is particularly troublesome.  The interfaces are:

+ jack_client : provides access to the jack subsystem. particularly important
  are the sampling rate and the functions to convert frame time to microseconds.
  Currently also does logging but this should probably be provided by a separate interface
+ data_thread : moves data from a fast to a slow thread. this also has a log
  function which should probably be factored out.
+ data_writer : stores data somewhere. also has a log function!

What I propose to do is move the logging functionality into a separate
interface, which should probably be implemented by data_writer derived classes.
jack_client can have a reference to the logger. One potentially tricky aspect is
that multiple threads may try to generate log messages and some locking is
needed. Right now I'm dealing with this using multiple inheritance from
data_thread and data_writer to generate concrete classes, but there may be a
better solution.

problem 1: arf_writer needs pointer to jack_client to get sampling rate and
resolve timestamps, and jack_client needs an event_logger reference to log its
events. One option would be to use a shared ptr for the jack_client (and perhaps
give arf_writer a boost::weak_ptr); the other would be to give arf_writer some
methods to set sampling rate. The timestamp resolution is harder. I could do the
conversion from frame count to usecs in multichannel_data_thread, but then that
means passing additional data to the data_writer....gah! I could also give
arf_writer a callback, but that's not super scalable. I think the weak reference
is the way to do it. Going to abstract out some of jack_client into data_client.

Okay, pretty good progress getting the logging code into a separate interface.
We now have:

+ data_source : provides sampling rate and functions to convert frame time to
  microseconds. base class for jack_client
+ data_writer : stores data somewhere. base for arf_writer
+ event_logger : writes log messages. base for arf_writer
+ data_thread : moves data from a fast to a slow thread. some implementation in buffered_data_thread.

The problem now is that simply providing the buffered_data_thread with access to
a data_writer means that anything accessing the writer through the data_writer
interface isn't going to be thread-safe.  Ideally the buffered_data_thread would
implement data_writer and event_logger.  But at the same time I don't want to
have the implementation of the arf-writing code in buffered_data_thread.

Can we have inheritance like this?

buffered_data_writer : public buffered_data_thread, public data_writer, public event_logger?

Or use a template?

template <typename DataWriter>
continuous_data_writer : public buffered_data_thread, public DataWriter

I think the tricky thing there is initializing DataWriter.

Or buffered_data_writer : public data_thread, public data_writer, public event_logger

The way I have things set up with the iostream proxy, event_logger::log()
returns an ostream that when flushed calls the derived class's log(msg)
function. This is the function that needs to lock a mutex. I suppose one option
is to own an data_writer reference, and also inherit from event_logger,
implementing the public functions in a thread-safe way. I could even require the
user to cede ownership of the data_writer.

[2013-03-28 Thu] Good progress; it's now possible to redirect the logstream
proxy to different event_logger objects, so buffered_data_writer can force
locking. Unfortunately this leads to deadlocks because the arf_writer class's
internal methods are now going through b_d_w. Option 1 - recursive locking. Not
too thrilled about this.  Another option is to factor out the locking that
protects the arf file from multiple write accesses into arf_writer, and just use
the lock in b_d_w for signalling the writer thread through a condition variable.
I think the place to implement this is in arf_writer itself because then I can
be pretty fine-grained.  This removes the need to have redirectable proxies.
The other place to do it is the arf c++ interface itself.  It adds a
compile-time dependency on boost threads, but that isn't so onerous.  The only
really tricky bit is that locking would need to be on the file level, and
objects only know about their containing file through hid_t objects, so the
handle::file() function actually creates a new object that other objects
wouldn't know about.  I could force objects to own a reference to the containing
object but that seems pretty hacky.

Settled on doing fine-grained locks in arf_writer. It may have slowed down the
writer quite a bit (though we are still getting > 4000 periods/s). need to do
some serious profiling at some non-premature point.

* DONE deal with pthread cleanup in destructors

Objects that own pthread objects (mutexes, condition variables) need to clean
them up on destruction. However, if the destructor gets called from a signal
handler, there's a chance of a deadlock (if the thread waiting on a condition
variable is the one that gets the signal, for example).  Signal handlers in
programs that uses these objects need to set some kind of shutdown flag, exit,
and let the threads exit naturally.  But of course this doesn't work without
signaling the condition variables, which isn't supported in signal handlers.
Some resources indicate only pthread_cancel is async-safe.

** DONE jstim

stimqueue waits in enqueue() and gets released by release(). Currently calling
enqueue() from main thread, but it's probably safer to spawn a separate thread
that can be canceled.

[2013-03-29 Fri] combining stimset and stimqueue into a single interface, and
then have a class readahead_stimqueue that implements it. process() accesses the
head of the queue through a pointer, and can release the pointer wait-free. the
main thread modifies the queue with add() and shuffle(), both of which reset the
queue to the beginning, but don't modify the head.

the queue spawns its own thread which takes care of putting elements from the
list into the head pointer. a bunch of conditions to check


** DONE jrecord

buffered_data_writer has a mutex and a condition variable. arf_writer also has a
mutex. there's some cleanup issues here, too, whereby arf_writer locks in order
to call the flush method.  Maybe that's not necessary?  I removed that (assuming
that the HDF5 library will clean itself up), and set the signal handler to just
tell the disk thread to stop, which will cause the program to exit normally.
* DONE jrecord: fix race condition with logger

when starting up a jrecord instance with a lot of channels, the first period may
arrive in the writer before all the mesages about port connection have been
emitted.  This situation could apply in other conditions as well. So clearly we
need some kind of blocking or queue for log messages.  may need to rethink this
whole effing thing.  I think the race condition is actually happening in the
boost::iostream - multiple threads are calling log() and getting the same stream.

settled on having a dedicated proxy class somewhat like make_string that
encapsulates a stringstream object, and that calls a private virtual function on
the event_logger that created it during destruction.  The stringstream is
allocated on the heap to allow the proxy to be easily copied.

* DONE arf_writer: fix cyclical reference problem

as noted earlier, arf_writer can use access to a data_source to calculate
samplerate and time information; jack_client needs access to an event_logger to
log events.  it doesn't work to use a weak_ptr in arf_writer that points to an
unallocated shared_ptr<data_source>, because resetting the
shared_ptr<data_source> doesn't magically update the weak_ptr.  Probably the
simplest (if somewhat inelegant) solution is to add a member function to
data_writer to set that pointer later.

* DONE jrecord should drop events before entry start

this was a bug in how the stored event time was calculated
* DONE handle disconnect of last trigger connection

need a threadsafe way to to do this that makes sure the full period is written
* DONE jstim: fix stimulus queue

this is still not behaving very well, althoguh it was working okay on os x.
partially a specification problem, an interface that's trying to do too much.
really what I need is a queue that will operate on a generic sequence. One
thread will run through the queue and load/resample the stimuli, while the RT
thread runs behind and consumes the elements in the queue.  The queue needs to
have an option to loop.  The other important element is being able to block the
main thread until the queue has been exhausted or interrupted.  Where the
problems are occurring are when the thread is running while stimuli are being
added to the list, so why not abstract this out.

* DONE terminate jentry on buffer size change
* DONE jstim doesnt't work with one stimulus

uninitialized variable in init_stimset

* DONE fix cascading xruns in jrecord

jrecord can have cascading xruns triggered by elsewhere in the system. I think
this comes about because process() keeps incrementing the xrun counter while the
disk thread is handling the previous xrun. One option would be to clear out the
read buffer; a better option would be to have the process loop stop adding data
to the buffer until the disk thread has dealt with the problem, though this
involves some careful signalling.  Need to keep in mind what's happening with
the triggered writer, which is currently specified not to close the entry.

rethinking the xrun handling. Instead of being an incrementing counter, should
be a state.  Other threads put a data_thread into an xrun state, which it
handles according to implementation, and then returns to a normal state.  The
implementation can also decide how to handle incoming data.  The RT thread
doesn't necessarily need to be aware of the xrun state.

Okay, I think I've got this working. buffered_data_writer::thread() handles the
Stopping state, but the virtual write() method handles the Xrun state.  This
means the period is passed to write() without checking whether it's null.

nope, it's still doing the silent fail. or else the jack daemon kills us,
supposedly because an upstream client fails. this can be either jstim or
jack_sequencer.  A problem in jack?

Can't test this using a output filestream in the process loop because there are
spikes in wait time writing to a file. Best bet is probably to monitor the
verbose output from jackd (a running indication of the delay for the process
graph). With one channel there is tons of headroom (21000+ usec), and writing is
stable for > 40 minutes.  Then the buffer fills and doesn't get emptied.

Ah hah! process() is checking the fill state of the buffer, and puts bdw back
into Xrun state, which means it never has a chance to clear itself.  The buffer
size check kind of breaks encapsulation under the new scheme.

Changed things around a bit to reduce the number of calls to trylock.  Seems
pretty stable now.

* TODO [#C] sample count not quite right in test_arf_thread

this may be an artifact of how the testing is done, but I'm short a few samples.
Appears to be fine in jrecord.

* TODO better handling of corrupted arf files

should happen in arf_writer

* DONE [#A] jstim: handle invalid stimulus files
* TODO jstim: mlock or otherwise ensure stimulus buffers aren't paged
* DONE [#A] jrecord won't trigger off jdetect

some broken logic in triggered_data_writer

* DONE [#B] jrecord: more flexible specification of input ports

spec says allow user to connect to all ports of another client, and to set up a
fixed number of ports. either drop from spec or implement

Probably the simplest thing would be, if the user specifies an input port that
doesn't exist, to just create a port with that name....done

* TODO [#C] replace pthread threading code with boost?

Would be more portable. might also deal with an annoying problem where pthreads
can reuse thread ids, so joining in the destructor of buffered_data_writer can
be problematic, if another thread has been started and takes the released id.
No problems as long as running only one thread, so maybe put this off for now.

* TODO testing and profiling

** DONE check for memory leaks

valgrind slows down the programs too much to run them under jack, so the tests
here are on the test programs.

boost::uuid generates a lot of uninitialized memory warnings, but that's part of
the implementation for randomness.

*** DONE jstim - test_stimset

*** DONE jdetect - counter, ringbuffer

*** DONE jrecord - ringbuffer, arf_writer, arf_thread

had to compile a test hdf5 library so I can run valgrind. arf_writer generates a
lot of reachable leaks from hdf5 calls. Some of these appear to be related to
cleanup of the packet tables. The size of the reachable memory doesn't increase
with multiple entries, so I'm going to conclude the library can take care of
itself on this front.

** TODO check for deadlocks

arf_thread's performance isn't quite what I'd like it to be, and it seems much
reduced after adding locking to arf_writer.  the granularity of the locks may be
too fine.

http://0pointer.de/blog/projects/mutrace.html

** DONE run jack_interposer
*** DONE jstim
*** DONE jdetect

failed the test because std::deque allocates memory. switched to a
boost::circular_buffer, passed.

*** DONE jrecord

** DONE test xrun handling

jstim and jdetect weren't closing with shutdown. needed handlers.

wrote a little xrun generator

** TODO stress tests

*** [2013-04-03 Wed]

run jstim, jdetect, and jrecord. Started jrecord at 1752, ran until 0007 after
creating 1008 entries and then died (error message is "Killed"). jack reports a
graph timeout from jstim first followed by a client disconnect from jrecord.
The kernel reports that it killed jrecord because it ran out of memory, so the
xrun in jstim may have been a consequence of that.

The test.arf file doesn't contain any entries, which suggests that the data were
never flushed to disk.

*** [2013-04-04 Thu]

run jrecord in continuous mode with 11 inputs. memory usage seems to
stabilize around ~3.6%. test.arf continues to grow.  however, at a certain point I
start seeing xruns (around 2GB).

set up test_arf_writer to write an arbitrary number of peirods. I do get
significant pauses, which are probably related to disk flushes.

now, it's possible this is an artifact of using the version of hdf5 that works
with valgrind. recompile with development hdf5 (is it threadsafe?). No, I still
get big pauses, and if anything they're worse.

One obvious solution is to increase the size of the ringbuffer.  Tried 256k
frames (1 MB), with a marginal improvement in uncompressed access.  Of course,
this is sort of what one expects given that buffering protects us from worst-case
scenarios rather than average.

Might also try increasing the chunk size in the arf packet tables.

in triggered mode with one channel, memory grows at a moderate pace, but doesn't
seem to stabilize. presumably this means there are unflushed resources.  With 12
channels the rate of growth is much, much faster.  If the unflushed resources
are packet tables (see above in memcheck section), this would be consistent with
the faster rate of growth.  Perhaps I should be trying to flush at some point.
I could either get the triggered_data_writer to do it during down time, or I
could add a flush statement to the h5pt destructor.  The latter is a cleaner
solution, though it does concentrate the load at a specific point.

Added a flush statement to the packet table destructor. Memory is still growing
uncontrollably.  Ah! The packet table identifier wasn't being freed.  Now the
memory stabilizes at 6.9% even when recording 12 channels.

back to continuous mode. With 12 channels, memory usage stabilizes around 6.7%
and cpu around 6.3%. the data don't seem to ever be flushed to disk, so I'm not
sure where it's living. One thought would be to call flush every so often, or
when the ringbuffer is empty. Hopefully by using idle cycles to take care of
disk stuff we can avoid huge pauses when closing entries, etc. Average cpu load
does appear to be a bit higher (10-11%). This should also work for
triggered_data_writer.

*** [2013-04-05 Fri]

Tried running jrecord with two channels overnight. It simply stopped writing
about a half hour after it was started. Looks like this is due to an xrun. The
reason it gets stuck in the xrun state is that data are no longer added to the
buffer, so the write() method that would clear the xrun flag never gets called.

Run again at the end of the day starting 1536 with jstim, jdetect, and jrecord.
The first xrun occurred at 20130406T013124.665242, which caused jstim to be
shutdown at 20130406T013124.686048. There was then a whole series of jack xruns
that were handled okay, than another round starting 20130406T183049.852681.
These were handled okay for a while, until 20130406T183050.985612 when the
program just quit. This coincided with jdetect getting shut down by jackd at
20130406T183050.915783.  Unfortunately the jackd log doesn't go back that far.

*** [2013-04-07 Sun]

Try running jstim and jdetect without jrecord to see if they stay stable.  I may
want to consider using -Z or a longer timeout so that clients are not being
kicked out.

As of Monday morning, no xruns or any other problems.  Not clear what caused
jstim to die Saturday morning.

*** [2013-04-08 Mon]

Try to get jstim to die by cranking the load.

: stress --cpu 8 --io 4 --vm 2 -d 2

Produces some nice spikes in load.  Everything seems stable.

Try to get jrecord to die by cranking load.  Seems fine.  Should probably
disable the onboard sound card.

Ran overnight. jdetect and jstim died, but not until about 843 on Tuesday,
coincidentally when I accessed the terminal. Interestingly, jrecord was still
functional and could be reconnected to jstim.

*** [2013-04-10 Wed]

still having problems with xruns bringing the system down. just running a couple
of jdetect processes overnight, both died due to alsa_pcm xruns (presumably
these arise from the sound card driver, which is another issue, possibly related
to this being a centos 6 machine)

seems like the xrun callback isn't returning a valid value.  Tried rewriting the
return statement, though I don't see what difference it should make.

