

* DONE fix storage of uuids

storing uuids as 16-byte strings is problematic because of nulls. change
specification to be either a 36-byte hex representation or a 128-bit integer.
The latter isn't supported on all platforms.

* DONE profile arf thread

using test_arf_thread I find a limit to how many channels I can write
simultaneously without causing buffer overruns. 100 is too many. Increasing the
JACK period size to 2048 helps. May need to increase ringbuffer size as well,
though I also got a malloc error when I tried to do 200 channels with a 2048
period.  The compression setting doesn't seem to make a difference.  Need to do
some serious profiling.

The first step is to try to factor out the jack client code so that the disk
code can be tested without needing to connect to the jack daemon.  It would
also be good to encapsulate as much of the mutex logic as possible.

I'm doing a rudimentary performance test by measuring how much have to throttle
back the fast thread in order not to have any xruns. For the "dummy writer",
which just talks to stdout, it seems like as long as the buffer is at least 5
times the size of the period, we only need a 1 ns throttle (plus whatever time
it takes to look up the current time). A 1024 sample period is ~ 200 us at 48
kHz, so this is more than fast enough for >256 channels.

Well, it makes a difference if I actually allow the data to go to stdout
instead of just redirecting to /dev/null. With no optimizations, a 20x buffer
needs a throttle of 4051 ns.

Let's see how the arf thread does.

With no optimizations I can do 12 channels and gzip1 compression with no
problems. Closing this for now.

* DONE fix port registration / buffer size bug

This is an annoying one. jack_client maintains a list of ports it has
registered, which it updates through the a port registration callback. This is a
nice solution that maintains a realtime-safe access point for the port list, but
these callbacks don't actually get called until the client is activated and
typically after the buffer size callback. In jrecord I'm using the buffer size
callback to adjust the size of the ringbuffer, but on the first call it doesn't
know how many ports are registered.

Fixed this by moving the port bookkeeping code to the register/unregister
functions. This should result in no loss of flexibility b/c other clients
shouldn't be doing anything with a module's ports anyway.

* DONE fix storage of event types

Event data will be stored in arrays with a compound datatype. Empty events are
discarded. Because the length of the message may vary, the bytes after the
status byte need to be stored in a variable length type. However, h5py cannot
read vlen types that are not strings!  Storing all event data in strings is
problematic, though, because normal MIDI messages are not null-terminated and
may in fact have \0 in them at various places.  Options are:

1. store the data in the correct format (char vlens) and try to fix h5py.
   definitely non-trivial.
2. translate all events into hex-encoded strings. This is pretty hacky and
   doubles the storage size.
3. translate standard midi messages into strings, e.g. "note on: 64 00".
   Probably the worst option because it locks in a specific interpretation of
   the messages

I think #2 is the best option at the moment, with a note that #1 may be
supported in the future.  I'm only going to require hex encoding for MIDI
messages with non-string payloads

* CANCELED abstract jack_client class?

should we anticipate non-jack data sources? Might make it easier to test.
However, there is a lot of jack-specific code elsewhere that would need to be
tracked down, including some of the major types that depend on JACK. See below.

* TODO replace pthread threading code with boost?

might be more portable

* DONE write trigger logic for arf_writer

This is moderately tricky because of the prebuffer. The function needs to

1) check whether the period is from the trigger port
2) if recording:
   1) if there was an offset event write data up to offset + postbuffer; copy
      remainder to prebuffer
   2) else, write all data
3) else:
   1) if there was an onset event, write data from prebuffer plus rest of period
   2) else, copy data to prebuffer

It's complicated enough I'm going to move the logic into a derived class. The
common logic for writing a period is now in do_write.

May be difficult to unit test this, although I can probably safely factor out
the prebuffering code.

The prebuffer is essentially a deque of period buffers.  We copy out the data
from the ringbuffer and put it in the queue.  When data falls off the end of
the queue it's released.  Really this should be implemented with a pool of
reusable memory to avoid calling malloc excessively.

Another option would be to allocate the ringbuffer large enough to hold the
prebuffer, and then simply retain the periods until they are far enough in the
past to discard.  The current implementation/interface isn't quite right for
this.

I wonder, what if I reimplemented the period ringbuffer using preallocated
structs rather than serializing. Instead of managing read/write pointers I'd be
managing a memory pool. Resizing the buffer would be messy because each of the
elements would have to be reallocated, but in practice this is not going to
happen much....okay, scratch this - it's really not much help - the real issue
is how =multichannel_writer= handles old data.

I think the thing to do is abstract the release operation through a virtual
function; deriving classes could then choose to hang on to extra frames. Or
implement a release() function in MCW that the write() funciton would call. Not
sure which is best practice, although the latter preserves encapsulation a bit
better.

Getting there...the period_ringbuffer class needs to be tweaked a bit to make it
useful as a prebuffer. Basically we need two read pointers - one that tracks the
"current" time, and another that is only advanced when the resources are
released.  Semantics of the interface should look something like this:

+ peek_newest - access the newest period and advance the peek pointer
+ peek_oldest - access the oldest period in the queue
+ release_oldest - advance the read pointer, releasing the oldest period in the queue
+ release_all - discard the data in the read buffer (e.g. when there is an xrun)

[2013-03-25 Mon] Good progress today, with many roadblocks. prebuffering works
great. post-trigger recording, not so much.  it's very tricky to figure out when
to terminate the recording, partly due to the annoyance of unsigned integer
arithemetic that needs to support overflow, and partly due to the fact that a
single period with multiple channels gets spread across multiple calls to
triggered_arf_thread::write().  One option would be to just drop the
post-trigger logic and force the upstream module generating events to wait
before issuing the offset.  This is simple but could lack some flexibility in
the future.

What the logic needs to do is figure out how many samples from the current
period need to be written, and if no samples need to be written, close the
entry.  There are three relevant variables: time at start of period; frames in
the period; and time of the offset event.

To deal with overflows, let's operate with deltas whenever possible, so
calculate (start - offset) and (start - offset + nframes).  The first of these
will overflow if the offset occurred in the current period

If start < offset < end, the offset event occurred in the current period. The
number of samples to be written is min(offset - start + npost, end - start)

[2013-03-26 Tue] Well, it's actually fairly simple. After the trigger I store
offset + posttrigger (i.e. the time to stop recording). In each successive
period I compare this value with the current time to determine whether this time
point has elapsed. The result of the comparison has to be stored in a signed
variable in case the offset occurred in the period before an overflow.  If it's
negative, then the offset has passed and the entry can be closed.

* DONE fix assertion failure in triggered_arf_thread

the failed assertion is that all the periods in the tail of the queue have been
flushed by the start_recording function.  I think it's failing because of how
the ringbuffer is implemented using mirrored memory - the same object can be
accessed by pointers with entirely different addresses, so the comparison can't
be made using addresses.

* DONE fix corrupted event

for some reason the first event stored by arf_writer is not properly stored and
appears as a bunch of junk

pathetic. was trying to store data from a stack-allocated string that went out
of scope.

* DONE refactor to create some better abstractions

Without necessarily trying to anticipate all possible data sources, etc, it
would be good at this stage to try to define some interfaces.  The challenge is
to try to limit the degree to which they have to interact with each other.  As
always, logging is particularly troublesome.  The interfaces are:

+ jack_client : provides access to the jack subsystem. particularly important
  are the sampling rate and the functions to convert frame time to microseconds.
  Currently also does logging but this should probably be provided by a separate interface
+ data_thread : moves data from a fast to a slow thread. this also has a log
  function which should probably be factored out.
+ data_writer : stores data somewhere. also has a log function!

What I propose to do is move the logging functionality into a separate
interface, which should probably be implemented by data_writer derived classes.
jack_client can have a reference to the logger. One potentially tricky aspect is
that multiple threads may try to generate log messages and some locking is
needed. Right now I'm dealing with this using multiple inheritance from
data_thread and data_writer to generate concrete classes, but there may be a
better solution.

problem 1: arf_writer needs pointer to jack_client to get sampling rate and
resolve timestamps, and jack_client needs an event_logger reference to log its
events. One option would be to use a shared ptr for the jack_client (and perhaps
give arf_writer a boost::weak_ptr); the other would be to give arf_writer some
methods to set sampling rate. The timestamp resolution is harder. I could do the
conversion from frame count to usecs in multichannel_data_thread, but then that
means passing additional data to the data_writer....gah! I could also give
arf_writer a callback, but that's not super scalable. I think the weak reference
is the way to do it. Going to abstract out some of jack_client into data_client.

Okay, pretty good progress getting the logging code into a separate interface.
We now have:

+ data_source : provides sampling rate and functions to convert frame time to
  microseconds. base class for jack_client
+ data_writer : stores data somewhere. base for arf_writer
+ event_logger : writes log messages. base for arf_writer
+ data_thread : moves data from a fast to a slow thread. some implementation in buffered_data_thread.

The problem now is that simply providing the buffered_data_thread with access to
a data_writer means that anything accessing the writer through the data_writer
interface isn't going to be thread-safe.  Ideally the buffered_data_thread would
implement data_writer and event_logger.  But at the same time I don't want to
have the implementation of the arf-writing code in buffered_data_thread.

Can we have inheritance like this?

buffered_data_writer : public buffered_data_thread, public data_writer, public event_logger?

Or use a template?

template <typename DataWriter>
continuous_data_writer : public buffered_data_thread, public DataWriter

I think the tricky thing there is initializing DataWriter.

Or buffered_data_writer : public data_thread, public data_writer, public event_logger

The way I have things set up with the iostream proxy, event_logger::log()
returns an ostream that when flushed calls the derived class's log(msg)
function. This is the function that needs to lock a mutex. I suppose one option
is to own an data_writer reference, and also inherit from event_logger,
implementing the public functions in a thread-safe way. I could even require the
user to cede ownership of the data_writer.

[2013-03-28 Thu] Good progress; it's now possible to redirect the logstream
proxy to different event_logger objects, so buffered_data_writer can force
locking. Unfortunately this leads to deadlocks because the arf_writer class's
internal methods are now going through b_d_w. Option 1 - recursive locking. Not
too thrilled about this.  Another option is to factor out the locking that
protects the arf file from multiple write accesses into arf_writer, and just use
the lock in b_d_w for signalling the writer thread through a condition variable.
I think the place to implement this is in arf_writer itself because then I can
be pretty fine-grained.  This removes the need to have redirectable proxies.
The other place to do it is the arf c++ interface itself.  It adds a
compile-time dependency on boost threads, but that isn't so onerous.  The only
really tricky bit is that locking would need to be on the file level, and
objects only know about their containing file through hid_t objects, so the
handle::file() function actually creates a new object that other objects
wouldn't know about.  I could force objects to own a reference to the containing
object but that seems pretty hacky.

Settled on doing fine-grained locks in arf_writer. It may have slowed down the
writer quite a bit (though we are still getting > 4000 periods/s). need to do
some serious profiling at some non-premature point.



* DONE deal with pthread cleanup in destructors

Objects that own pthread objects (mutexes, condition variables) need to clean
them up on destruction. However, if the destructor gets called from a signal
handler, there's a chance of a deadlock (if the thread waiting on a condition
variable is the one that gets the signal, for example).  Signal handlers in
programs that uses these objects need to set some kind of shutdown flag, exit,
and let the threads exit naturally.  But of course this doesn't work without
signaling the condition variables, which isn't supported in signal handlers.
Some resources indicate only pthread_cancel is async-safe.

** DONE jstim

stimqueue waits in enqueue() and gets released by release(). Currently calling
enqueue() from main thread, but it's probably safer to spawn a separate thread
that can be canceled.

[2013-03-29 Fri] combining stimset and stimqueue into a single interface, and
then have a class readahead_stimqueue that implements it. process() accesses the
head of the queue through a pointer, and can release the pointer wait-free. the
main thread modifies the queue with add() and shuffle(), both of which reset the
queue to the beginning, but don't modify the head.

the queue spawns its own thread which takes care of putting elements from the
list into the head pointer. a bunch of conditions to check


** DONE jrecord

buffered_data_writer has a mutex and a condition variable. arf_writer also has a
mutex. there's some cleanup issues here, too, whereby arf_writer locks in order
to call the flush method.  Maybe that's not necessary?  I removed that (assuming
that the HDF5 library will clean itself up), and set the signal handler to just
tell the disk thread to stop, which will cause the program to exit normally.

* DONE jrecord: fix race condition with logger

when starting up a jrecord instance with a lot of channels, the first period may
arrive in the writer before all the mesages about port connection have been
emitted.  This situation could apply in other conditions as well. So clearly we
need some kind of blocking or queue for log messages.  may need to rethink this
whole effing thing.  I think the race condition is actually happening in the
boost::iostream - multiple threads are calling log() and getting the same stream.

settled on having a dedicated proxy class somewhat like make_string that
encapsulates a stringstream object, and that calls a private virtual function on
the event_logger that created it during destruction.  The stringstream is
allocated on the heap to allow the proxy to be easily copied.

* DONE arf_writer: fix cyclical reference problem

as noted earlier, arf_writer can use access to a data_source to calculate
samplerate and time information; jack_client needs access to an event_logger to
log events.  it doesn't work to use a weak_ptr in arf_writer that points to an
unallocated shared_ptr<data_source>, because resetting the
shared_ptr<data_source> doesn't magically update the weak_ptr.  Probably the
simplest (if somewhat inelegant) solution is to add a member function to
data_writer to set that pointer later.

* TODO sample count not quite right in test_arf_thread

this may be an artifact of how the testing is done, but I'm short a few samples.
Appears to be fine in jrecord.

* DONE jrecord should drop events before entry start

this was a bug in how the stored event time was calculated
* TODO handle disconnect of last trigger connection

need a threadsafe way to to do this that makes sure the full period is written

* TODO test xrun handling

* TODO jrecord: more flexible specification of input ports

spec says allow user to connect to all ports of another client, and to set up a
fixed number of ports. either drop from spec or implement

* DONE terminate jentry on buffer size change
* TODO profiling

arf_thread's performance isn't quite what I'd like it to be, and it seems much
reduced after adding locking to arf_writer.  the granularity of the locks may be
too fine.

** TODO check for deadlocks
