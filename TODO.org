
* DONE fix storage of uuids

storing uuids as 16-byte strings is problematic because of nulls. change
specification to be either a 36-byte hex representation or a 128-bit integer.
The latter isn't supported on all platforms.

* DONE profile arf thread

using test_arf_thread I find a limit to how many channels I can write
simultaneously without causing buffer overruns. 100 is too many. Increasing the
JACK period size to 2048 helps. May need to increase ringbuffer size as well,
though I also got a malloc error when I tried to do 200 channels with a 2048
period.  The compression setting doesn't seem to make a difference.  Need to do
some serious profiling.

The first step is to try to factor out the jack client code so that the disk
code can be tested without needing to connect to the jack daemon.  It would
also be good to encapsulate as much of the mutex logic as possible.

I'm doing a rudimentary performance test by measuring how much have to throttle
back the fast thread in order not to have any xruns. For the "dummy writer",
which just talks to stdout, it seems like as long as the buffer is at least 5
times the size of the period, we only need a 1 ns throttle (plus whatever time
it takes to look up the current time). A 1024 sample period is ~ 200 us at 48
kHz, so this is more than fast enough for >256 channels.

Well, it makes a difference if I actually allow the data to go to stdout
instead of just redirecting to /dev/null. With no optimizations, a 20x buffer
needs a throttle of 4051 ns.

Let's see how the arf thread does.

With no optimizations I can do 12 channels and gzip1 compression with no
problems. Closing this for now.

* DONE fix port registration / buffer size bug

This is an annoying one. jack_client maintains a list of ports it has
registered, which it updates through the a port registration callback. This is a
nice solution that maintains a realtime-safe access point for the port list, but
these callbacks don't actually get called until the client is activated and
typically after the buffer size callback. In jrecord I'm using the buffer size
callback to adjust the size of the ringbuffer, but on the first call it doesn't
know how many ports are registered.

Fixed this by moving the port bookkeeping code to the register/unregister
functions. This should result in no loss of flexibility b/c other clients
shouldn't be doing anything with a module's ports anyway.

* DONE fix storage of event types

Event data will be stored in arrays with a compound datatype. Empty events are
discarded. Because the length of the message may vary, the bytes after the
status byte need to be stored in a variable length type. However, h5py cannot
read vlen types that are not strings!  Storing all event data in strings is
problematic, though, because normal MIDI messages are not null-terminated and
may in fact have \0 in them at various places.  Options are:

1. store the data in the correct format (char vlens) and try to fix h5py.
   definitely non-trivial.
2. translate all events into hex-encoded strings. This is pretty hacky and
   doubles the storage size.
3. translate standard midi messages into strings, e.g. "note on: 64 00".
   Probably the worst option because it locks in a specific interpretation of
   the messages

I think #2 is the best option at the moment, with a note that #1 may be
supported in the future.  I'm only going to require hex encoding for MIDI
messages with non-string payloads

* CANCELED abstract jack_client class?

should we anticipate non-jack data sources? Might make it easier to test.
However, there is a lot of jack-specific code elsewhere that would need to be
tracked down, including some of the major types that depend on JACK. See below.

* DONE write trigger logic for arf_writer

This is moderately tricky because of the prebuffer. The function needs to

1) check whether the period is from the trigger port
2) if recording:
   1) if there was an offset event write data up to offset + postbuffer; copy
      remainder to prebuffer
   2) else, write all data
3) else:
   1) if there was an onset event, write data from prebuffer plus rest of period
   2) else, copy data to prebuffer

It's complicated enough I'm going to move the logic into a derived class. The
common logic for writing a period is now in do_write.

May be difficult to unit test this, although I can probably safely factor out
the prebuffering code.

The prebuffer is essentially a deque of period buffers.  We copy out the data
from the ringbuffer and put it in the queue.  When data falls off the end of
the queue it's released.  Really this should be implemented with a pool of
reusable memory to avoid calling malloc excessively.

Another option would be to allocate the ringbuffer large enough to hold the
prebuffer, and then simply retain the periods until they are far enough in the
past to discard.  The current implementation/interface isn't quite right for
this.

I wonder, what if I reimplemented the period ringbuffer using preallocated
structs rather than serializing. Instead of managing read/write pointers I'd be
managing a memory pool. Resizing the buffer would be messy because each of the
elements would have to be reallocated, but in practice this is not going to
happen much....okay, scratch this - it's really not much help - the real issue
is how =multichannel_writer= handles old data.

I think the thing to do is abstract the release operation through a virtual
function; deriving classes could then choose to hang on to extra frames. Or
implement a release() function in MCW that the write() funciton would call. Not
sure which is best practice, although the latter preserves encapsulation a bit
better.

Getting there...the period_ringbuffer class needs to be tweaked a bit to make it
useful as a prebuffer. Basically we need two read pointers - one that tracks the
"current" time, and another that is only advanced when the resources are
released.  Semantics of the interface should look something like this:

+ peek_newest - access the newest period and advance the peek pointer
+ peek_oldest - access the oldest period in the queue
+ release_oldest - advance the read pointer, releasing the oldest period in the queue
+ release_all - discard the data in the read buffer (e.g. when there is an xrun)

[2013-03-25 Mon] Good progress today, with many roadblocks. prebuffering works
great. post-trigger recording, not so much.  it's very tricky to figure out when
to terminate the recording, partly due to the annoyance of unsigned integer
arithemetic that needs to support overflow, and partly due to the fact that a
single period with multiple channels gets spread across multiple calls to
triggered_arf_thread::write().  One option would be to just drop the
post-trigger logic and force the upstream module generating events to wait
before issuing the offset.  This is simple but could lack some flexibility in
the future.

What the logic needs to do is figure out how many samples from the current
period need to be written, and if no samples need to be written, close the
entry.  There are three relevant variables: time at start of period; frames in
the period; and time of the offset event.

To deal with overflows, let's operate with deltas whenever possible, so
calculate (start - offset) and (start - offset + nframes).  The first of these
will overflow if the offset occurred in the current period

If start < offset < end, the offset event occurred in the current period. The
number of samples to be written is min(offset - start + npost, end - start)

[2013-03-26 Tue] Well, it's actually fairly simple. After the trigger I store
offset + posttrigger (i.e. the time to stop recording). In each successive
period I compare this value with the current time to determine whether this time
point has elapsed. The result of the comparison has to be stored in a signed
variable in case the offset occurred in the period before an overflow.  If it's
negative, then the offset has passed and the entry can be closed.

* DONE fix assertion failure in triggered_arf_thread

the failed assertion is that all the periods in the tail of the queue have been
flushed by the start_recording function.  I think it's failing because of how
the ringbuffer is implemented using mirrored memory - the same object can be
accessed by pointers with entirely different addresses, so the comparison can't
be made using addresses.

* DONE fix corrupted event

for some reason the first event stored by arf_writer is not properly stored and
appears as a bunch of junk

pathetic. was trying to store data from a stack-allocated string that went out
of scope.

* DONE refactor to create some better abstractions

Without necessarily trying to anticipate all possible data sources, etc, it
would be good at this stage to try to define some interfaces.  The challenge is
to try to limit the degree to which they have to interact with each other.  As
always, logging is particularly troublesome.  The interfaces are:

+ jack_client : provides access to the jack subsystem. particularly important
  are the sampling rate and the functions to convert frame time to microseconds.
  Currently also does logging but this should probably be provided by a separate interface
+ data_thread : moves data from a fast to a slow thread. this also has a log
  function which should probably be factored out.
+ data_writer : stores data somewhere. also has a log function!

What I propose to do is move the logging functionality into a separate
interface, which should probably be implemented by data_writer derived classes.
jack_client can have a reference to the logger. One potentially tricky aspect is
that multiple threads may try to generate log messages and some locking is
needed. Right now I'm dealing with this using multiple inheritance from
data_thread and data_writer to generate concrete classes, but there may be a
better solution.

problem 1: arf_writer needs pointer to jack_client to get sampling rate and
resolve timestamps, and jack_client needs an event_logger reference to log its
events. One option would be to use a shared ptr for the jack_client (and perhaps
give arf_writer a boost::weak_ptr); the other would be to give arf_writer some
methods to set sampling rate. The timestamp resolution is harder. I could do the
conversion from frame count to usecs in multichannel_data_thread, but then that
means passing additional data to the data_writer....gah! I could also give
arf_writer a callback, but that's not super scalable. I think the weak reference
is the way to do it. Going to abstract out some of jack_client into data_client.

Okay, pretty good progress getting the logging code into a separate interface.
We now have:

+ data_source : provides sampling rate and functions to convert frame time to
  microseconds. base class for jack_client
+ data_writer : stores data somewhere. base for arf_writer
+ event_logger : writes log messages. base for arf_writer
+ data_thread : moves data from a fast to a slow thread. some implementation in buffered_data_thread.

The problem now is that simply providing the buffered_data_thread with access to
a data_writer means that anything accessing the writer through the data_writer
interface isn't going to be thread-safe.  Ideally the buffered_data_thread would
implement data_writer and event_logger.  But at the same time I don't want to
have the implementation of the arf-writing code in buffered_data_thread.

Can we have inheritance like this?

buffered_data_writer : public buffered_data_thread, public data_writer, public event_logger?

Or use a template?

template <typename DataWriter>
continuous_data_writer : public buffered_data_thread, public DataWriter

I think the tricky thing there is initializing DataWriter.

Or buffered_data_writer : public data_thread, public data_writer, public event_logger

The way I have things set up with the iostream proxy, event_logger::log()
returns an ostream that when flushed calls the derived class's log(msg)
function. This is the function that needs to lock a mutex. I suppose one option
is to own an data_writer reference, and also inherit from event_logger,
implementing the public functions in a thread-safe way. I could even require the
user to cede ownership of the data_writer.

[2013-03-28 Thu] Good progress; it's now possible to redirect the logstream
proxy to different event_logger objects, so buffered_data_writer can force
locking. Unfortunately this leads to deadlocks because the arf_writer class's
internal methods are now going through b_d_w. Option 1 - recursive locking. Not
too thrilled about this.  Another option is to factor out the locking that
protects the arf file from multiple write accesses into arf_writer, and just use
the lock in b_d_w for signalling the writer thread through a condition variable.
I think the place to implement this is in arf_writer itself because then I can
be pretty fine-grained.  This removes the need to have redirectable proxies.
The other place to do it is the arf c++ interface itself.  It adds a
compile-time dependency on boost threads, but that isn't so onerous.  The only
really tricky bit is that locking would need to be on the file level, and
objects only know about their containing file through hid_t objects, so the
handle::file() function actually creates a new object that other objects
wouldn't know about.  I could force objects to own a reference to the containing
object but that seems pretty hacky.

Settled on doing fine-grained locks in arf_writer. It may have slowed down the
writer quite a bit (though we are still getting > 4000 periods/s). need to do
some serious profiling at some non-premature point.

* DONE deal with pthread cleanup in destructors

Objects that own pthread objects (mutexes, condition variables) need to clean
them up on destruction. However, if the destructor gets called from a signal
handler, there's a chance of a deadlock (if the thread waiting on a condition
variable is the one that gets the signal, for example).  Signal handlers in
programs that uses these objects need to set some kind of shutdown flag, exit,
and let the threads exit naturally.  But of course this doesn't work without
signaling the condition variables, which isn't supported in signal handlers.
Some resources indicate only pthread_cancel is async-safe.

** DONE jstim

stimqueue waits in enqueue() and gets released by release(). Currently calling
enqueue() from main thread, but it's probably safer to spawn a separate thread
that can be canceled.

[2013-03-29 Fri] combining stimset and stimqueue into a single interface, and
then have a class readahead_stimqueue that implements it. process() accesses the
head of the queue through a pointer, and can release the pointer wait-free. the
main thread modifies the queue with add() and shuffle(), both of which reset the
queue to the beginning, but don't modify the head.

the queue spawns its own thread which takes care of putting elements from the
list into the head pointer. a bunch of conditions to check


** DONE jrecord

buffered_data_writer has a mutex and a condition variable. arf_writer also has a
mutex. there's some cleanup issues here, too, whereby arf_writer locks in order
to call the flush method.  Maybe that's not necessary?  I removed that (assuming
that the HDF5 library will clean itself up), and set the signal handler to just
tell the disk thread to stop, which will cause the program to exit normally.
* DONE jrecord: fix race condition with logger

when starting up a jrecord instance with a lot of channels, the first period may
arrive in the writer before all the mesages about port connection have been
emitted.  This situation could apply in other conditions as well. So clearly we
need some kind of blocking or queue for log messages.  may need to rethink this
whole effing thing.  I think the race condition is actually happening in the
boost::iostream - multiple threads are calling log() and getting the same stream.

settled on having a dedicated proxy class somewhat like make_string that
encapsulates a stringstream object, and that calls a private virtual function on
the event_logger that created it during destruction.  The stringstream is
allocated on the heap to allow the proxy to be easily copied.

* DONE arf_writer: fix cyclical reference problem

as noted earlier, arf_writer can use access to a data_source to calculate
samplerate and time information; jack_client needs access to an event_logger to
log events.  it doesn't work to use a weak_ptr in arf_writer that points to an
unallocated shared_ptr<data_source>, because resetting the
shared_ptr<data_source> doesn't magically update the weak_ptr.  Probably the
simplest (if somewhat inelegant) solution is to add a member function to
data_writer to set that pointer later.

* DONE jrecord should drop events before entry start

this was a bug in how the stored event time was calculated
* DONE handle disconnect of last trigger connection

need a threadsafe way to to do this that makes sure the full period is written
* DONE jstim: fix stimulus queue

this is still not behaving very well, althoguh it was working okay on os x.
partially a specification problem, an interface that's trying to do too much.
really what I need is a queue that will operate on a generic sequence. One
thread will run through the queue and load/resample the stimuli, while the RT
thread runs behind and consumes the elements in the queue.  The queue needs to
have an option to loop.  The other important element is being able to block the
main thread until the queue has been exhausted or interrupted.  Where the
problems are occurring are when the thread is running while stimuli are being
added to the list, so why not abstract this out.

* DONE terminate jentry on buffer size change
* DONE jstim doesnt't work with one stimulus

uninitialized variable in init_stimset

* DONE fix cascading xruns in jrecord

jrecord can have cascading xruns triggered by elsewhere in the system. I think
this comes about because process() keeps incrementing the xrun counter while the
disk thread is handling the previous xrun. One option would be to clear out the
read buffer; a better option would be to have the process loop stop adding data
to the buffer until the disk thread has dealt with the problem, though this
involves some careful signalling.  Need to keep in mind what's happening with
the triggered writer, which is currently specified not to close the entry.

rethinking the xrun handling. Instead of being an incrementing counter, should
be a state.  Other threads put a data_thread into an xrun state, which it
handles according to implementation, and then returns to a normal state.  The
implementation can also decide how to handle incoming data.  The RT thread
doesn't necessarily need to be aware of the xrun state.

Okay, I think I've got this working. buffered_data_writer::thread() handles the
Stopping state, but the virtual write() method handles the Xrun state.  This
means the period is passed to write() without checking whether it's null.

nope, it's still doing the silent fail. or else the jack daemon kills us,
supposedly because an upstream client fails. this can be either jstim or
jack_sequencer.  A problem in jack?

Can't test this using a output filestream in the process loop because there are
spikes in wait time writing to a file. Best bet is probably to monitor the
verbose output from jackd (a running indication of the delay for the process
graph). With one channel there is tons of headroom (21000+ usec), and writing is
stable for > 40 minutes.  Then the buffer fills and doesn't get emptied.

Ah hah! process() is checking the fill state of the buffer, and puts bdw back
into Xrun state, which means it never has a chance to clear itself.  The buffer
size check kind of breaks encapsulation under the new scheme.

Changed things around a bit to reduce the number of calls to trylock.  Seems
pretty stable now.

* TODO [#C] sample count not quite right in test_arf_thread

this may be an artifact of how the testing is done, but I'm short a few samples.
Appears to be fine in jrecord.

* TODO better handling of corrupted arf files

should happen in arf_writer

* DONE [#A] jstim: handle invalid stimulus files
* TODO jstim: mlock or otherwise ensure stimulus buffers aren't paged
* DONE [#A] jrecord won't trigger off jdetect

some broken logic in triggered_data_writer

* DONE [#B] jrecord: more flexible specification of input ports

spec says allow user to connect to all ports of another client, and to set up a
fixed number of ports. either drop from spec or implement

Probably the simplest thing would be, if the user specifies an input port that
doesn't exist, to just create a port with that name....done

* TODO [#C] replace pthread threading code with boost?

Would be more portable. might also deal with an annoying problem where pthreads
can reuse thread ids, so joining in the destructor of buffered_data_writer can
be problematic, if another thread has been started and takes the released id.
No problems as long as running only one thread, so maybe put this off for now.

* DONE fix jstim sample length issue

This bug was encountered in the process of writing util/adjust_stimtimes.py

Found a mismatch between the recorded trigger times and the duration of the
stimulus. If I correct for onset delay and plot the actual stimulus over the
recorded stimulus, the match is almost perfect. But the offset time is short by
609 samples (stimulus is 'bk196_ref_3x'). Is this a problem with the old data?
Checked logfile from jrecord 2.1 and the stimulus duration matches the pre/post
trigger times in the logfile, and the times in the trig_in dataset. Apparently
an error. Also wrong in next entry. I guess I should check for this but only
flag it if the file is pre 2.1.

Fourth, file-level QC. Collect delays for all entries, and flag any entries
that deviate from the mean by more than a couple of samples.

Wow! The file I'm using to test this algorithm has delays that are all over the
place. My guess is that alsa_out started doing its pathological cycling.  Will
run a quick dummy experiment with jill 2.1 to see if this is better.

Getting some really weird results. First, a sanity check is whether recorded
stimuli look the same in different entries. No, not really. Wtf! the offsets
aren't the same in multiple reps of the same stimulus!

Okay, try to reproduce the problem in a simpler environment. Use audio card
only. Quick test of loopback delay indicates it's rock-solid. Record both the
jstim signal, the loopback signal, and the trigger info. Present the same 5
stimuli 10 times each. First run was with non-debug versions of the jill
programs.

One thing I notice is that some entries end before the next entry starts. Is
the sample count of the subsequent entry correct?

Compare reference and loopback signals for first stimulus: cross-correlation
estimate of delay is 2109 samples, agreeing nicely with jack_delay's estimate of
2108.67. The end of the signal also agrees perfectly with the offset time in
trig_in.

Now compare offset times of entries with identical stimuli. Mismatch! Holy eff.
Looked at reference recording. First ~877 samples are identical, and then they
aren't. jstim is apparently dropping samples. Well, this is clearly a huge
problem. And it probably explains why the delay estimates were so all over the
map.

Other entries with the same stimulus have the same set of initial samples, but
break off at a different point.  My guess is that the first block of samples
get played after the stimulus is triggered, and then that the counter gets
advanced too far in the next period.  Support for this is that the divergent
samples appear to be identical to stim[1024:2048].

Yep, should be subtracting period_offset from nframes when calculating the
number of frames to copy. Amazingly this was not causing segfaults, because I
was running over the buffer.

Rerun test: reference stims align perfectly. Loopback stimuli align perfectly,
with the addition of some line noise. Repated presentations of the same stimulus
have the same offset.

Test full rhd/alsa configuration. Max delay jitter is 3 samples between stimuli
and 2 samples between onset and offset.

* DONE more useful errors with bad commandline options
  CLOCK: [2013-05-15 Wed 14:28]--[2013-05-15 Wed 14:45] =>  0:17

in particular, failure to load an ini file

* TODO write zmq ipc protocol

The idea is to provide a mechanism for programs to influence the behavior of
running clients. This is a fairly low priority task. Move to 2_2 milestone.

* DONE replace complicated logging mechanism with simple zmq-based one

Constraints:

1. Support multiple backends, including interprocess communication
2. Reentrant.
3. Possibly, safe to call from the RT thread (no mallocs, no locks).

The pattern I'm using for logging seems pretty sound (temporary object
encapsulating a ostringstream). The change would be to have a singleton object
that manages sinks. One interesting idea would be to use zmq to transmit log
messages to arf_writer, which could write the messages when it has time and
would eliminate the need for locking.

[2013-08-07 Wed] okay, implementing the singleton was easy and does clean stuff
up a lot. It also encapsulates all the zmq ipc code, which currently doesn't do
anything because there's no sockets to bind to. Deal with that once I refactor
the buffered data writer bidniss.

[2013-08-09 Fri] Starting work on this again. It's fairly easy to get the logger
class to create a zmq socket and send messages to it, but one caveat is that
sockets can't be shared among threads, so that makes the log calls unsafe. Could
use mutexes. Not RT-safe, but it's not safe anyway to log due to mallocs in
stringstream. It seems a little hacky, but logging is infrequent, so the chances
of lock contention are probably pretty low, and it concentrates the locking in
one well-defined place.

Another issue is related to connections. One nice feature of zmq is that the
server doesn't have to be bound when the clients connect, so log messages would
be stored until a server binds. However, I think these just sit in memory, so a
really long-running process could suck up a lot of memory.  Let some processes
run for a while and the memory is growing quite modestly, so I think this isn't
a problem.  However, the buffered_writer thread needs to only process limited
numbers of messages between cycles to avoid getting swamped if the queue is
really full.

Finally, the router socket in jrecord should really use the same context as the
dealer in the same process, but using a singleton to manage access may create
some problems in cleanup. I suppose one possibility would be for logger to
expose its context.  No, that doesn't work because the logger destructor goes
off first and blocks on destroying the context.  Just use a second context if
no other arguments against.

Next up, write a simple standalone client that pulls messages off the queue and
prints them.

* DONE write jclick: transforms event input into clicks on an audio output
  CLOSED: [2013-06-10 Mon 11:31]

* DONE write jill tutorial
    CLOSED: [2013-07-01 Mon 12:16]

[[file:~/Devel/jill/doc/user_guide.org][jill user guide]]

* DONE fix frame count when entries are closed
    CLOSED: [2013-08-09 Fri 12:36]

Subtracting the frame count when the entry started from the frame count when it
ended (in the log) yields a number consistently smaller than the number of
frames in the datasets. Suspect this is because the value in
arf_writer::close_entry is associated with the period start, not the period
end, but there could be a deeper problem.

[[file:~/Devel/jill/jill/file/arf_writer.cc::o%20<<%20"closed%20entry:%20"%20<<%20_entry->name()%20<<%20"%20(frame%3D"%20<<%20_period_start%20<<%20")"%3B][arf_writer::close_entry]]

* DONE contemplate sample clock jitter
    CLOSED: [2013-07-03 Wed 09:04]

[2013-07-02 Tue] In developing mspikes 3.0, which supports both real and
sampled time bases, I discovered that the sample clock values and the timestamp
values in the created ARF files were not consistent.  That is, the system time
between entries and the number of frames is not exactly the nominal sampling
rate, and there's some degree of jitter.  This seems to be the case for ARF
files generated by jill using the intan board or a sound card.

As noted in the link below, this is related to the fact that there's an
uncontrollable delay between the soundcard interrupt and the time when the
process callback is called:

http://lists.jackaudio.org/htdig.cgi/jack-devel-jackaudio.org/2008-August/000999.html

For an ARF file created with a sound card, the nominal rate was 48000, the mean
rate was 48001, and the standard deviation was 57 samples.  The jitter with the
microsecond clock was less.  Average rate was 48002, SD = 1.06.

For an ARF file created with saber, the nominal rate was 20000, the mean rate
was 20000.02, with SD = 3.46.

For an ARF file created with the intan driver, the nominal rate was 30000.
Actual rate was 30000.5, SD = 123.  Using the usec counter, actual rate was
29999.9, SD = 0.27.

I believe the lower jitter between the sample counter and the usec clock is
related to the fact that JACK uses a delay locked loop (DLL) for the microsecond
timer. So the real problem is that the timestamps are a bit imprecise.  It's
probably exacerbated by the fact that I look up the time at some separate point.

Patched arf_writer.cc to register the jack usec counter against the system
clock when it's connected to the jack client.  Then, when a new entry is
created, the frame count is converted to a usec value, and the difference
between that value and the base is used to set the timestamp.  Greatly reduces
jitter on all accounts - on a very long run SD was 0.03 frames.

* DONE document stimulus table in arf files
  CLOSED: [2013-07-03 Wed 13:09]
  CLOCK: [2013-07-03 Wed 10:50]--[2013-07-03 Wed 10:51] =>  0:01
* DONE update jill user guide with mac install instructions
  CLOSED: [2013-07-03 Wed 12:44]
  CLOCK: [2013-07-03 Wed 10:51]--[2013-07-03 Wed 10:51] =>  0:00
* DONE post jill user guide to github
  CLOSED: [2013-07-03 Wed 12:44]
  CLOCK: [2013-07-03 Wed 10:52]--[2013-07-03 Wed 10:52] =>  0:00
* DONE figure out why jrecord corrupts event log on OS X Lion
    CLOSED: [2013-08-01 Thu 15:42]

first, are the midi messages themselves being corrupted? Yes. See next item.

* DONE figure out why jrecord 2.0.2 won't close entries
    CLOSED: [2013-08-09 Fri 12:36]

[2013-08-01 Thu] looks like it's only getting the start events, and none of the
data. blerg!. On my mac, I'm getting some kind of stop event, but it's complete
garbage except for the time. Okay, on modeln it seems to be working fine.
Differences: jack1 vs jack2; an older jill version (before fix to timestamps).
Try compiling more recent version. Works fine. Try installing jack1 on birdsong.
Okay, that works. What's puzzling is that the jack midi monitor works fine under
jack2, which implies that the messages are traveling fine. Oh, I wonder if I
need to recompile against the jack2 libraries. Nope! Okay, so jack_midi_dump is
linked against the old libjack. Recompile against new jack, same result. So
presumably something in jill.

So what I'm getting is a buffer full of zeros. Possibly the mechanics of how
jack2 is storing midi data have changed, such that simply copying the buffer to
the ringbuffer is no longer effective.  I think for some message sizes jack
uses a different memory area, maybe this has changed.  Ah, it's 4 bytes in
0.121, but much larger in 0.118. Hah! That's what I get for using a nonstandard
API.  Clearly this is related to the bug I was seeing on Lion.

Fixing this is going to require a rethink of the ringbuffer, or how I'm using
it. I think I need to read and serialize the midi data in the RT thread and
write a chunk to the ringbuffer that just contains the parsed data. Data is
variable length, which adds some complexity.

For sampled data the serialized period looks like:

+ time
+ nframes
+ arg (pointer to port object)
+ data (nframes * sizeof(sample_t) bytes)

The port object is used to look up the channel name and the data type.
Conceivably this could be used to indicate to arf_writer how to handle the
data, although perhaps an even better idea is to abstract out the jack
dependence altogther. Maybe something like:

#+begin_src c++
  struct period_info_t {
          enum ctype_t {
                  sampled = 0,
                  event = 1
          };
          nframes_t time;       // time of the data
          nframes_t size;       // number of bytes following header
          ctype_t chan_type;    // type of data
          char chan_name[some_max];
          char data[size];
  };
#+end_src

If chan_type is sampled, data is an array of floats. If not, it's a series of
variable-length structures with the following fields:

#+begin_src c++
  struct event_t {
          nframes_t time;  // relative to start of period
          nframes_t size;  // number of bytes in buffer
          unsigned char data[size]; // message
  };
#+end_src

Another possibility would be to just use an entire period chunk for each event,
which might be even simpler. I'm not sure about sending the channel name in each
chunk. It does eliminate the dependency on jack which is nice. The max size is
256 bytes, which is a lot of useless data. Could use a null-terminated string,
of course...

#+begin_src c++
  enum dtype_t {
          sampled = 0,
          event = 1
  };
  nframes_t offset;       // sample count
  dtype_t dtype;          // sampled or event
  size_t id_sz;           // size of id string
  size_t data_sz;         // number of bytes in data
  char id[id_sz];         // channel name or id
  // data serialization depends on value of dtype:
  // sampled: array of data_sz / sizeof(sample_t)
  // event: array of data_sz bytes
  char data[data_sz];
#+end_src

Renamed period_ringbuffer -> block_ringbuffer and added dtype and channel name
arguments to the push method. The classes that interact with this are
buffered_data_writer, triggered_data_writer, and jrecord's process function.
Edit the process function first to see how painful serialization will be.

[2013-08-02 Fri] period_info_t is no more, which means a lot of interfaces will
change. It would be nice to encapsulate deserialization a bit more so that we're
not having to pass around pointers to data_source objects, etc. Because
deserialization takes place in a slow thread, it can use dynamically-allocated
resources. More copying, but that may be a small price to pay for simplicity.

Another failure of encapsulation is the logging functionality; I wonder if it
wouldn't be worth tackling that first.

[2013-08-07 Wed] Done fixing logging (at least on one end), back to refactoring
data flow. The constraint is that the serializing thread (pushing data to the
ringbuffer) is realtime and shouldn't look up port names or try to convert frame
counts to useconds. So the deserializer (pulling data from the ringbuffer)
needs access to the jack_client handle to resolve those questions.  This should
happen as early as possible so that the consumers (arf_writer, etc) can be
ignorant of where their data comes from.

Right now the deserializer is effectively the data_thread class
(buffered_data_writer or triggered_data_writer), which is also responsible
for managing the ringbuffer as a prebuffer, closing and opening entries in
arf_writer, handling xruns, etc. It's kind of a mess, especially with
triggering.

* DONE figure out and document netjack
    CLOSED: [2013-08-01 Thu 08:35]

The goal is one-way communication from one jack daemon (master, connected to a
microphone) and to another (slave, connected to speakers).

I think jack2 is probably the best bet here. For one reason, in jack1 you have
to connect the master to the slave, which is somewhat bass-ackwards.

On debian end: sudo apt-get install jackd2 (will uninstall jackd1)

On mac end: install jackosx (0.90)

jacktrip is a user-space client that seems to be fairly straightforward. The
buffer size and sampling rate do have to be the same, but this is a pretty
minor restriction. Added some instructions to the wiki

Resources:

[[http://trac.jackaudio.org/wiki/WalkThrough/User/NetJack][WalkThrough/User/NetJack - Jack Audio Connection Kit - Trac]]
[[http://www.trac.jackaudio.org/wiki/WalkThrough/User/NetJack2][WalkThrough/User/NetJack2 - Jack Audio Connection Kit - Trac]]
[[http://code.google.com/p/jacktrip/][jacktrip - A System for High-Quality Audio Network Performance over the Internet. - Google Project Hosting]]
* DONE jrecord xruns

jrecord is indicating xruns, but they aren't coming from jack AFAICT. Only
seems to happen with a lot of channels. Happens even when in triggered mode but
not writing anything.

caused by ringbuffer overruns

looks like I forgot to multiply the number of frames by sizeof(sample_t) when
setting ringbuffer size.

* testing and profiling

** DONE check for memory leaks

valgrind slows down the programs too much to run them under jack, so the tests
here are on the test programs.

boost::uuid generates a lot of uninitialized memory warnings, but that's part of
the implementation for randomness.

*** DONE jstim - test_stimset

*** DONE jdetect - counter, ringbuffer

*** DONE jrecord - ringbuffer, arf_writer, arf_thread

had to compile a test hdf5 library so I can run valgrind. arf_writer generates a
lot of reachable leaks from hdf5 calls. Some of these appear to be related to
cleanup of the packet tables. The size of the reachable memory doesn't increase
with multiple entries, so I'm going to conclude the library can take care of
itself on this front.

** TODO check for deadlocks

arf_thread's performance isn't quite what I'd like it to be, and it seems much
reduced after adding locking to arf_writer.  the granularity of the locks may be
too fine.

http://0pointer.de/blog/projects/mutrace.html

** DONE run jack_interposer
*** DONE jstim
*** DONE jdetect

failed the test because std::deque allocates memory. switched to a
boost::circular_buffer, passed.

*** DONE jrecord

** DONE test xrun handling

jstim and jdetect weren't closing with shutdown. needed handlers.

wrote a little xrun generator

** TODO stress tests

*** [2013-04-03 Wed]

run jstim, jdetect, and jrecord. Started jrecord at 1752, ran until 0007 after
creating 1008 entries and then died (error message is "Killed"). jack reports a
graph timeout from jstim first followed by a client disconnect from jrecord.
The kernel reports that it killed jrecord because it ran out of memory, so the
xrun in jstim may have been a consequence of that.

The test.arf file doesn't contain any entries, which suggests that the data were
never flushed to disk.

*** [2013-04-04 Thu]

run jrecord in continuous mode with 11 inputs. memory usage seems to
stabilize around ~3.6%. test.arf continues to grow.  however, at a certain point I
start seeing xruns (around 2GB).

set up test_arf_writer to write an arbitrary number of peirods. I do get
significant pauses, which are probably related to disk flushes.

now, it's possible this is an artifact of using the version of hdf5 that works
with valgrind. recompile with development hdf5 (is it threadsafe?). No, I still
get big pauses, and if anything they're worse.

One obvious solution is to increase the size of the ringbuffer.  Tried 256k
frames (1 MB), with a marginal improvement in uncompressed access.  Of course,
this is sort of what one expects given that buffering protects us from worst-case
scenarios rather than average.

Might also try increasing the chunk size in the arf packet tables.

in triggered mode with one channel, memory grows at a moderate pace, but doesn't
seem to stabilize. presumably this means there are unflushed resources.  With 12
channels the rate of growth is much, much faster.  If the unflushed resources
are packet tables (see above in memcheck section), this would be consistent with
the faster rate of growth.  Perhaps I should be trying to flush at some point.
I could either get the triggered_data_writer to do it during down time, or I
could add a flush statement to the h5pt destructor.  The latter is a cleaner
solution, though it does concentrate the load at a specific point.

Added a flush statement to the packet table destructor. Memory is still growing
uncontrollably.  Ah! The packet table identifier wasn't being freed.  Now the
memory stabilizes at 6.9% even when recording 12 channels.

back to continuous mode. With 12 channels, memory usage stabilizes around 6.7%
and cpu around 6.3%. the data don't seem to ever be flushed to disk, so I'm not
sure where it's living. One thought would be to call flush every so often, or
when the ringbuffer is empty. Hopefully by using idle cycles to take care of
disk stuff we can avoid huge pauses when closing entries, etc. Average cpu load
does appear to be a bit higher (10-11%). This should also work for
triggered_data_writer.

*** [2013-04-05 Fri]

Tried running jrecord with two channels overnight. It simply stopped writing
about a half hour after it was started. Looks like this is due to an xrun. The
reason it gets stuck in the xrun state is that data are no longer added to the
buffer, so the write() method that would clear the xrun flag never gets called.

Run again at the end of the day starting 1536 with jstim, jdetect, and jrecord.
The first xrun occurred at 20130406T013124.665242, which caused jstim to be
shutdown at 20130406T013124.686048. There was then a whole series of jack xruns
that were handled okay, than another round starting 20130406T183049.852681.
These were handled okay for a while, until 20130406T183050.985612 when the
program just quit. This coincided with jdetect getting shut down by jackd at
20130406T183050.915783.  Unfortunately the jackd log doesn't go back that far.

*** [2013-04-07 Sun]

Try running jstim and jdetect without jrecord to see if they stay stable.  I may
want to consider using -Z or a longer timeout so that clients are not being
kicked out.

As of Monday morning, no xruns or any other problems.  Not clear what caused
jstim to die Saturday morning.

*** [2013-04-08 Mon]

Try to get jstim to die by cranking the load.

: stress --cpu 8 --io 4 --vm 2 -d 2

Produces some nice spikes in load.  Everything seems stable.

Try to get jrecord to die by cranking load.  Seems fine.  Should probably
disable the onboard sound card.

Ran overnight. jdetect and jstim died, but not until about 843 on Tuesday,
coincidentally when I accessed the terminal. Interestingly, jrecord was still
functional and could be reconnected to jstim.

*** [2013-04-10 Wed]

still having problems with xruns bringing the system down. just running a couple
of jdetect processes overnight, both died due to alsa_pcm xruns (presumably
these arise from the sound card driver, which is another issue, possibly related
to this being a centos 6 machine)

seems like the xrun callback isn't returning a valid value.  Tried rewriting the
return statement, though I don't see what difference it should make.

*** [2013-05-15 Wed]

Try another run on debian 7. Non-RT kernel.  Simple triggered capture.
